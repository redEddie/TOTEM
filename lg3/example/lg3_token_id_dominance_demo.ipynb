{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LG3 token dominance inspection (top code id)\n",
        "\n",
        "This notebook finds the most frequent token id and visualizes where it dominates in time.\n",
        "It uses SMARTCARE per-unit data (unit 1, 4, 6) and a trained LG3 VQ-VAE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e832260",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sys.path.append(os.path.abspath('../..'))\n",
        "\n",
        "# Paths\n",
        "LG3_VQVAE_CKPT = '../saved_models/CD64_CW256_CF4_BS2048_ITR15000/checkpoints/final_model.pth'\n",
        "UNIT_IDS = [1, 4, 6]\n",
        "UNIT_ROOT = os.path.abspath(os.path.join('..', 'data', 'processed', 'smartcare_units'))\n",
        "PROCESSED_DIR = os.path.abspath(os.path.join('..', 'data', 'processed'))\n",
        "\n",
        "SEQ_LEN = 96\n",
        "SAMPLE_SEQS = 2000  # per unit\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "FEATURE_NAME = 'Power'  # feature to plot (must exist in unit csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3f6221d",
      "metadata": {},
      "source": [
        "## 1) Load model and helpers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fa763cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from lg3.lib.models.revin import RevIN\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "model = torch.load(LG3_VQVAE_CKPT, weights_only=False).to(device).eval()\n",
        "compression_factor = getattr(model, 'compression_factor', 4)\n",
        "\n",
        "def build_sequences(values, seq_len):\n",
        "    total = len(values)\n",
        "    max_start = total - seq_len + 1\n",
        "    if max_start <= 0:\n",
        "        return None\n",
        "    x = np.empty((max_start, seq_len, values.shape[1]), dtype=np.float32)\n",
        "    for i in range(max_start):\n",
        "        x[i] = values[i : i + seq_len]\n",
        "    return x\n",
        "\n",
        "def time2codes(revin_data, compression_factor, vqvae_encoder, vqvae_quantizer):\n",
        "    bs = revin_data.shape[0]\n",
        "    nvar = revin_data.shape[1]\n",
        "    t_len = revin_data.shape[2]\n",
        "    compressed_time = int(t_len / compression_factor)\n",
        "    with torch.no_grad():\n",
        "        flat_revin = revin_data.reshape(-1, t_len)\n",
        "        latent = vqvae_encoder(flat_revin.to(torch.float), compression_factor)\n",
        "        vq_loss, quantized, perplexity, embedding_weight, encoding_indices, encodings = vqvae_quantizer(latent)\n",
        "        code_ids = encoding_indices.view(bs, nvar, compressed_time)\n",
        "    return code_ids.detach().cpu().numpy()\n",
        "\n",
        "def encode_sequences(x, revin_layer):\n",
        "    # x: (B, T, S)\n",
        "    x_t = torch.tensor(x, dtype=torch.float32, device=device)\n",
        "    x_norm = revin_layer(x_t, 'norm')\n",
        "    code_ids = time2codes(x_norm.permute(0, 2, 1), compression_factor, model.encoder, model.vq)\n",
        "    return code_ids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "482f1a03",
      "metadata": {},
      "source": [
        "## 2) Collect code usage and find top id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf89d83",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_codes = []\n",
        "meta = {}\n",
        "\n",
        "train_path = os.path.join(PROCESSED_DIR, 'lg3_train.csv')\n",
        "if not os.path.exists(train_path):\n",
        "    raise FileNotFoundError(train_path)\n",
        "\n",
        "df = pd.read_csv(train_path, index_col=0, parse_dates=True)\n",
        "df = df.select_dtypes(include=[np.number]).dropna(how='any')\n",
        "if FEATURE_NAME not in df.columns:\n",
        "    raise ValueError(f'{FEATURE_NAME} not found in {train_path}')\n",
        "\n",
        "x = build_sequences(df.values, SEQ_LEN)\n",
        "if x is None:\n",
        "    raise RuntimeError('Not enough data')\n",
        "\n",
        "# sample sequences for speed\n",
        "if len(x) > SAMPLE_SEQS:\n",
        "    idx = np.random.choice(len(x), size=SAMPLE_SEQS, replace=False)\n",
        "    x = x[idx]\n",
        "    ts = df.index[idx + SEQ_LEN - 1]\n",
        "else:\n",
        "    ts = df.index[SEQ_LEN - 1:]\n",
        "\n",
        "revin = RevIN(num_features=x.shape[2], affine=False, subtract_last=False).to(device)\n",
        "\n",
        "# batch encode\n",
        "codes = []\n",
        "for i in range(0, len(x), BATCH_SIZE):\n",
        "    batch = x[i:i+BATCH_SIZE]\n",
        "    codes.append(encode_sequences(batch, revin))\n",
        "code_ids = np.concatenate(codes, axis=0)\n",
        "\n",
        "all_codes.append(code_ids)\n",
        "meta[\"all\"] = {'timestamps': ts, 'codes': code_ids, 'values': df}\n",
        "\n",
        "flat_codes = np.concatenate([c.reshape(-1) for c in all_codes], axis=0)\n",
        "counts = np.bincount(flat_codes)\n",
        "top_id = int(np.argmax(counts))\n",
        "print('Top code id:', top_id, 'count:', counts[top_id], 'total:', counts.sum())\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(counts)\n",
        "plt.title('Code usage histogram (all data)')\n",
        "plt.xlabel('code id')\n",
        "plt.ylabel('count')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1189c563",
      "metadata": {},
      "source": [
        "## 3) Visualize top-id dominance over time\n",
        "For each unit, compute the fraction of top-id tokens per sequence and plot over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e626308b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.dates as mdates\n",
        "def top_id_ratio(code_ids, top_id):\n",
        "    # code_ids shape: (B, S, Tcomp)\n",
        "    total = code_ids.shape[1] * code_ids.shape[2]\n",
        "    hits = (code_ids == top_id).sum(axis=(1, 2))\n",
        "    return hits / total\n",
        "\n",
        "def plot_ratio_scatter(ts, ratios, unit_id):\n",
        "    # Plot in 4-day windows\n",
        "    start = ts.min().normalize()\n",
        "    end = ts.max().normalize()\n",
        "    window = pd.Timedelta(days=4)\n",
        "    cur = start\n",
        "    \n",
        "    while cur <= end:\n",
        "        nxt = cur + window\n",
        "        mask = (ts >= cur) & (ts < nxt)\n",
        "        \n",
        "        if mask.any():\n",
        "            plt.figure(figsize=(10, 3))\n",
        "            plt.scatter(ts[mask], ratios[mask], s=8, color='red')\n",
        "            \n",
        "            ax = plt.gca()\n",
        "            \n",
        "            # 1. 포맷 및 간격 설정\n",
        "            ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))\n",
        "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
        "            ax.xaxis.set_minor_locator(mdates.HourLocator(interval=1))\n",
        "            \n",
        "            # 2. 그리드 설정\n",
        "            ax.grid(True, which='major', axis='both', linestyle='--', alpha=0.3)\n",
        "            ax.grid(True, which='minor', axis='both', linestyle='--', alpha=0.2)\n",
        "            \n",
        "            # 3. 레이블 회전 및 정렬 (핵심!)\n",
        "            # ha='right'를 해야 날짜 끝부분이 눈금에 맞춰집니다.\n",
        "            # plt.xticks(rotation=45, ha='right') \n",
        "            plt.gcf().autofmt_xdate()\n",
        "            \n",
        "            # 만약 폰트를 줄이고 싶다면 아래처럼 fontsize를 추가하세요\n",
        "            # plt.xticks(rotation=45, ha='right', fontsize=8) \n",
        "\n",
        "            plt.title(f'Unit {unit_id} - top id ratio ({cur.date()} ~ {(nxt - pd.Timedelta(days=1)).date()})')\n",
        "            plt.ylabel('ratio')\n",
        "            \n",
        "            plt.tight_layout() # 여백 자동 조정\n",
        "            plt.show()\n",
        "            \n",
        "        cur = nxt\n",
        "\n",
        "for unit_id, meta in unit_meta.items():\n",
        "    ratios = top_id_ratio(meta['codes'], top_id)\n",
        "    ts = pd.to_datetime(meta['timestamps'])\n",
        "    plot_ratio_scatter(ts, ratios, unit_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e543ac",
      "metadata": {},
      "source": [
        "## 4) Overlay top-id spikes with raw feature (single unit)\n",
        "We highlight sequences where top-id ratio is high.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "944331b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# (기존 데이터 준비 코드는 그대로 유지)\n",
        "meta = meta[\"all\"]\n",
        "ratios = top_id_ratio(meta[\"codes\"], top_id)\n",
        "ts = pd.to_datetime(meta[\"timestamps\"])\n",
        "\n",
        "threshold = np.quantile(ratios, 0.55)\n",
        "high = ratios >= threshold\n",
        "\n",
        "feature_series = meta[\"values\"][FEATURE_NAME]\n",
        "\n",
        "# Plot in 4-day windows\n",
        "start = feature_series.index.min().normalize()\n",
        "end = feature_series.index.max().normalize()\n",
        "window = pd.Timedelta(days=4)\n",
        "cur = start\n",
        "\n",
        "while cur <= end:\n",
        "    nxt = cur + window\n",
        "    seg = feature_series[(feature_series.index >= cur) & (feature_series.index < nxt)]\n",
        "\n",
        "    if len(seg) == 0:\n",
        "        cur = nxt\n",
        "        continue\n",
        "\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.plot(seg.index, seg.values, color=\"black\", linewidth=0.8)\n",
        "\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # 1. X축 눈금 및 포맷 설정\n",
        "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d %H:%M\"))\n",
        "    ax.xaxis.set_minor_locator(mdates.HourLocator(interval=1))\n",
        "\n",
        "    # 2. 그리드 설정\n",
        "    ax.grid(True, which=\"major\", axis=\"both\", linestyle=\"--\", alpha=0.3)\n",
        "    ax.grid(True, which=\"minor\", axis=\"both\", linestyle=\"--\", alpha=0.2)\n",
        "\n",
        "    # 3. 레이블 회전 설정\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "\n",
        "    plt.title(f\"{FEATURE_NAME} ({cur.date()} ~ {(nxt - pd.Timedelta(days=1)).date()})\")\n",
        "\n",
        "    # mark high-ratio windows (as points)\n",
        "    mask = (ts >= cur) & (ts < nxt)\n",
        "    if mask.any():\n",
        "        valid_indices = high[mask]\n",
        "        target_ts = ts[mask][valid_indices]\n",
        "        try:\n",
        "            target_vals = seg.reindex(target_ts).values\n",
        "            plt.scatter(target_ts, target_vals, color=\"red\", s=12, zorder=5)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping scatter due to index mismatch: {e}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    cur = nxt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eb0f97e",
      "metadata": {},
      "source": [
        "## 5) What pattern does the top token represent?\n",
        "We decode a sequence made entirely of the top id and plot its reconstructed waveform.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "596c5dc4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decode a pure top-id sequence to visualize its waveform\n",
        "codebook = model.vq._embedding.weight.detach().cpu().numpy()\n",
        "code_dim = codebook.shape[1]\n",
        "tcomp = SEQ_LEN // compression_factor\n",
        "\n",
        "# Build a quantized tensor: [B, code_dim, tcomp]\n",
        "vec = codebook[top_id]  # (code_dim,)\n",
        "quantized = np.tile(vec.reshape(1, code_dim, 1), (1, 1, tcomp))\n",
        "q_t = torch.tensor(quantized, dtype=torch.float32, device=device)\n",
        "with torch.no_grad():\n",
        "    recon = model.decoder(q_t, compression_factor).detach().cpu().numpy()[0]\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(recon, color='purple')\n",
        "plt.title(f'Decoded waveform of top id {top_id}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0637255d",
      "metadata": {},
      "source": [
        "Optional: compare with average of high-ratio sequences.\n",
        "- top_id_ratio(meta[\"codes\"], top_id) → 각 시퀀스마다 “top_id가 얼마나 많이 등장했는지” 비율을 계산\n",
        "- high = ratios >= np.quantile(ratios, 0.95) → 그 비율이 상위 5%인 시퀀스만 선택\n",
        "- mean_pattern = x[high].mean(axis=0) → 그 “top_id가 지배적인” 시퀀스들의 평균 패턴을 시각화\n",
        "\n",
        "즉, 가장 빈번한 토큰이 많이 등장하는 구간들이 어떤 형태의 시계열을 가지는지를 보는 시각화예요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa37364d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# meta = meta[\"all\"]\n",
        "ratios = top_id_ratio(meta[\"codes\"], top_id)\n",
        "ts = pd.to_datetime(meta[\"timestamps\"])\n",
        "\n",
        "feature_name = \"Power\"  # 시각화 원하는 컬럼명\n",
        "# Rebuild sequences for this dataset to compute mean pattern\n",
        "df = meta[\"values\"]\n",
        "feature_idx = df.select_dtypes(include=[np.number]).columns.get_loc(feature_name)\n",
        "values = df.select_dtypes(include=[np.number]).values\n",
        "x = build_sequences(values, SEQ_LEN)\n",
        "if x is not None:\n",
        "    # align x length with ratios length\n",
        "    max_len = min(len(x), len(ratios))\n",
        "    x = x[:max_len]\n",
        "    ratios = ratios[:max_len]\n",
        "    high = ratios >= np.quantile(ratios, 0.95)\n",
        "    mean_pattern = x[high].mean(axis=0)\n",
        "    # plot one feature (first column)\n",
        "    plt.figure(figsize=(8, 3))\n",
        "    plt.plot(mean_pattern[:, feature_idx], color=\"black\")\n",
        "    plt.title(f\"Average high-ratio sequence (feature idx {feature_idx}, {feature_name})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Not enough data to compute mean pattern\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "totme",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
